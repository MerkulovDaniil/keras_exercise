{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "CPython 2.7.12\n",
      "IPython 5.1.0\n",
      "\n",
      "scipy 0.18.1\n",
      "sklearn 0.18.1\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)\n",
      "system     : Darwin\n",
      "release    : 16.4.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p scipy,sklearn,numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n",
      "Classes: \n",
      "[0 1]\n",
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# summarize number of classes\n",
    "print(\"Classes: \")\n",
    "print(numpy.unique(y))\n",
    "\n",
    "# summarize number of words\n",
    "print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10893ee50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize review length\n",
    "print(\"Review length: \")\n",
    "result = map(len, X)\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           4000250     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             251         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 20s - loss: 0.5098 - acc: 0.7143 - val_loss: 0.3166 - val_acc: 0.8636\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 20s - loss: 0.2005 - acc: 0.9237 - val_loss: 0.3049 - val_acc: 0.8734\n",
      "Accuracy: 87.34%\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=2, batch_size=128, verbose=1)\n",
    "\n",
    "# final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)\n",
    "\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 500, 32)       160000      embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 500, 32)       3104        embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 250, 32)       0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 8000)          0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 250)           2000250     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             251         dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 23s - loss: 0.4222 - acc: 0.7794 - val_loss: 0.2899 - val_acc: 0.8776\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 22s - loss: 0.2202 - acc: 0.9140 - val_loss: 0.2845 - val_acc: 0.8821\n",
      "Accuracy: 88.21%\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=2, batch_size=128, verbose=1)\n",
    "\n",
    "# final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
